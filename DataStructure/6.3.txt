The first baseline system is a bag-of-words model. Step one is to train a word embedding by [2]. This word embedding pro- vides the word vector for each token in the question and its candidate answer. From these, the baseline system produces the idf-weighted sum of word vectors for the question and for all of its answer candidates. This produces a vector represen- tation for the question and each answer candidate. The last step is to calculate the cosine similarity between each ques- tion/candidate pair. The pair with highest cosine similarity is returned as the answer. The second baseline is an information retrieval (IR) baseline. The state-of-the-art weighted depen- dency model (WD) [3, 4] is used. The WD model employs a weighted combination of term-based and term proximity- based ranking features to score each candidate answer. Ex- ample features include counts of question bigrams in ordered and unordered windows of different sizes in each candidate answer, in addition to simple unigram counts. The basic idea is that important bigrams or unigrams in the question should receive higher weights when their frequencies are computed. Thus, the feature weights are assigned in accordance to the importance of the question unigrams or bigrams that they are defined over, where the importance factor is learned as part of the model training process. Row 1 and 2 (first column Idx) of Table 2 are the baseline system results.